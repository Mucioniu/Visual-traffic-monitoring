{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import glob\n",
    "import sys \n",
    "import cv2 as cv\n",
    "import pdb\n",
    "import numpy as np\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "# Load YOLO\n",
    "net = cv.dnn.readNet(\"yolov4-p6.weights\", \"yolov4-p6.cfg\")\n",
    "\n",
    "# Load classes\n",
    "classes = []\n",
    "\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "print(classes)\n",
    "# Get the indices of the output layers\n",
    "layer_ids = net.getUnconnectedOutLayers()\n",
    "layer_names = net.getLayerNames()\n",
    "# Retrieve the names of the output layers\n",
    "output_layers = [layer_names[layer_id - 1] for layer_id in layer_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lane polygons\n",
    "drawed_lanes = [\n",
    "    np.array([[401, 388], [191, 195], [102, 220], [224, 408]], np.int32),\n",
    "    np.array([[407, 389], [191, 195], [208, 137], [529, 377]], np.int32),\n",
    "    np.array([[531, 376], [208, 137], [268, 120], [645, 370]], np.int32),\n",
    "    np.array([[1177, 305], [1648, 305], [1665, 340], [1177, 388]], np.int32),\n",
    "    np.array([[1177,390], [1665, 345], [1682, 364], [1235,414]], np.int32),\n",
    "    np.array([[1235,415], [1660, 366], [1701, 396], [1288,440]], np.int32),\n",
    "    np.array([[1411, 608], [1878, 839], [1639, 876], [1237, 638]], np.int32),\n",
    "    np.array([[1237, 638], [1639, 876], [1396, 876], [1075, 660]], np.int32),\n",
    "    np.array([[1075, 660], [1396, 876], [1183, 875], [944, 686]], np.int32)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main block that generate all the txt files.\n",
    "def solve_all_images(images_path, queries_path,drawed_lanes):\n",
    "    queries = glob.glob(os.path.join(queries_path, \"*_*_query.txt\"))\n",
    "    all_queries =[]\n",
    "    all_images = []\n",
    "\n",
    "    # Loop through the file list and read in each file\n",
    "    for filename in queries:\n",
    "        with open(filename, 'r') as file:\n",
    "            file_contents = file.readlines()\n",
    "            all_queries.append(file_contents)\n",
    "                \n",
    "    #The local path for the images path from a single game\n",
    "    images = glob.glob(os.path.join(images_path,\"*_*.jpg\"))\n",
    "    for image_path in images:\n",
    "        image = cv.imread(image_path)\n",
    "        all_images.append(image)\n",
    "\n",
    "    #iterate over every image and compute the txt file\n",
    "    for i in range(0,len(images)):\n",
    "        image = all_images[i]\n",
    "        height, width, channels = image.shape\n",
    "\n",
    "        # Preprocess image\n",
    "        blob = cv.dnn.blobFromImage(image, 0.00892, (1280, 1280), (0, 0, 0), True, crop=False)\n",
    "\n",
    "        # Set input to the network\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Run forward pass\n",
    "        outs = net.forward(output_layers)\n",
    "\n",
    "        # Initialize lists for bounding boxes, confidences, and class IDs\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for out in outs:\n",
    "            for detection in out:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if class_id != 9 and class_id != 58 and class_id != 0:  # Class ID 2 represents cars in COCO dataset\n",
    "                    # Scale bounding box coordinates to the original image size\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    # Calculate top-left coordinates of bounding box\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    # Store bounding box, confidence, and class ID\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # Apply non-maximum suppression to remove overlapping bounding boxes\n",
    "        indexes = cv.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "        # Initialize a list to store occupied lane indices\n",
    "        occupied_lanes = []\n",
    "\n",
    "        # Iterate through the lanes\n",
    "        for lane_index, drawed_lane in enumerate(drawed_lanes):\n",
    "            # Check if any vehicle overlaps with the current lane\n",
    "            for box_index in range(len(boxes)):\n",
    "                if box_index in indexes:\n",
    "                    x, y, w, h = boxes[box_index]\n",
    "\n",
    "                    # Calculate the y-coordinate of the lower third of the bounding box\n",
    "                    lower_third_y = y + int(h * 2 / 3.1)\n",
    "\n",
    "                    #For lane 4 all the area is representative\n",
    "                    if lane_index == 3:\n",
    "                        if cv.pointPolygonTest(drawed_lane, (x + w / 2, y + h / 2), False) >= 0:\n",
    "                            # Lane is occupied by a vehicle\n",
    "                            occupied_lanes.append(lane_index + 1)\n",
    "                            break\n",
    "                    # Check if the lower third of the bounding box overlaps with the lane\n",
    "                    else:\n",
    "                        if cv.pointPolygonTest(drawed_lane, (x + w / 2, lower_third_y), False) >= 0:\n",
    "                            # Lane is occupied by a vehicle\n",
    "                            occupied_lanes.append(lane_index + 1)\n",
    "                            break\n",
    "\n",
    "        # Get the number of queries and lanes from the corresponding files\n",
    "        num_queries = int(all_queries[i][0].strip())\n",
    "        lanes = [int(line.strip()) for line in all_queries[i][1:]]\n",
    "\n",
    "        # Determine the image prefix based on the image number\n",
    "        image_num = i + 1\n",
    "        if image_num <= 30:\n",
    "            image_prefix = \"{:02d}\".format((image_num - 1) // 3 + 1)\n",
    "            query_range = range(1, 4)  # Set query_suffix range to 1-3\n",
    "            query_suffix = str(query_range[(image_num - 1) % len(query_range)])\n",
    "        else:\n",
    "            image_prefix = \"{:02d}\".format((image_num - 31) // 4 + 11)\n",
    "            query_range = range(1, 5)  # Set query_suffix range to 1-4\n",
    "            query_suffix = str(query_range[(image_num - 3) % len(query_range)])\n",
    "        \n",
    "\n",
    "        # Construct the output file name\n",
    "        output_file_name = \"results_task1/{}_{}_predicted.txt\".format(image_prefix, query_suffix)\n",
    "\n",
    "\n",
    "        # Create the output .txt file\n",
    "        with open(output_file_name, \"w\") as output_file:\n",
    "            output_file.write(str(num_queries) + \"\\n\")\n",
    "\n",
    "            for lane in lanes:\n",
    "                if lane in occupied_lanes:\n",
    "                    output_file.write(str(lane) + \" 1\\n\")\n",
    "                else:\n",
    "                    output_file.write(str(lane) + \" 0\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = \"test/Task1\"\n",
    "queries = \"test/Task1\"\n",
    "solve_all_images(images,queries,drawed_lanes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
