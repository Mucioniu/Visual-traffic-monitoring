{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import sys \n",
    "import cv2 as cv\n",
    "import pdb\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_all_videos(videos_path, text_files_path):\n",
    "    # Get a list of all text files in the specified path\n",
    "    text_files = glob.glob(os.path.join(text_files_path, \"*.txt\"))\n",
    "    all_text_files = []  # Store the contents of all text files\n",
    "    all_videos = []  # Store all video objects\n",
    "\n",
    "    # Loop through the file list and read in each file\n",
    "    for filename in text_files:\n",
    "        with open(filename, 'r') as file:\n",
    "            file_contents = file.readlines()\n",
    "            all_text_files.append(file_contents)\n",
    "\n",
    "    # Get a list of all video files in the specified path\n",
    "    videos = glob.glob(os.path.join(videos_path, \"*.mp4\"))\n",
    "\n",
    "    for video_path in videos:\n",
    "        video = cv.VideoCapture(video_path)\n",
    "        all_videos.append(video)\n",
    "\n",
    "    # Iterate over every video and compute the txt file\n",
    "    for i in range(len(all_videos)):\n",
    "        # Creates an instance of the DaSiamRPN tracker object using the attached files\n",
    "        tracker = cv.TrackerDaSiamRPN_create()\n",
    "\n",
    "        # Select the video for processing\n",
    "        cap = all_videos[i]\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        output = []  # Store the output lines for the txt file\n",
    "        output_array = None  # Store the output bounding box coordinates as an array\n",
    "        x1, y1, x2, y2 = None, None, None, None  # Initial bounding box coordinates\n",
    "\n",
    "        # Read and process the lines from the corresponding text file\n",
    "        lines = [line.strip() for line in all_text_files[i]]\n",
    "        for idx, line in enumerate(lines):\n",
    "            output.append(line)\n",
    "\n",
    "            # Extract the bounding box coordinates from the second line\n",
    "            if idx == 1:\n",
    "                f, x1, y1, x2, y2 = map(int, line.split(\" \"))\n",
    "                output.append('\\n')\n",
    "                output_array = np.array([f, x1, x2, y1, y2])\n",
    "\n",
    "        bbox = (x1, y1, x2 - x1, y2 - y1)  # Bounding box format: (x, y, width, height)\n",
    "        tracker.init(frame, bbox)  # Initialize the tracker with the first frame and bounding box\n",
    "\n",
    "        frame_counter = 1  # Initialize frame counter\n",
    "\n",
    "        def drawBox(img, bbox):\n",
    "            # Draw bounding box on the image\n",
    "            x, y, w, h = map(int, bbox)\n",
    "            cv.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3, 3)\n",
    "\n",
    "        while True:\n",
    "            success, img = cap.read()  # Read the next frame from the video\n",
    "\n",
    "            if not success:\n",
    "                break  # Break if no more frames are available\n",
    "\n",
    "            success, bbox = tracker.update(img)  # Update the tracker with the current frame\n",
    "\n",
    "            # Output the results as long as the tracker is active\n",
    "            if success:\n",
    "                drawBox(img, bbox)  # Draw the bounding box on the image\n",
    "                x, y, w, h = map(int, bbox)  # Extract the updated bounding box coordinates\n",
    "\n",
    "                # Append the frame number and bounding box coordinates to the output\n",
    "                output.append(f\"{frame_counter} {x} {y} {x+w} {y+h}\\n\")\n",
    "                output_array = np.vstack((output_array, np.array([frame_counter, x, y, x+w, y+h])))\n",
    "\n",
    "            # Break if the object goes out of bounds or shrinks below a certain size\n",
    "            if (x < 0 or y < 0 or x + w > img.shape[1] or y + h > img.shape[0]) and (w < (x2 - x1) / 2.25 or h < (y2 - y1) / 2.25):\n",
    "                break\n",
    "\n",
    "            #cv.imshow(\"Tracking\", img)  # Display the image with tracking information\n",
    "            key = cv.waitKey(1) & 0xff  # Check for keyboard input\n",
    "            if key == ord('q'):\n",
    "                break  # Break if 'q' is pressed\n",
    "\n",
    "            frame_counter += 1  # Increment frame counter\n",
    "\n",
    "        with open(f\"results_task2/{i+1:02d}_predicted.txt\", 'w') as file:\n",
    "            file.write(' '.join(output))  # Write the output lines to the txt file\n",
    "\n",
    "\n",
    "    cap.release()  # Release the video capture object\n",
    "    cv.destroyAllWindows()  # Close any open windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_path = \"test/Task2\"\n",
    "text_files_path = \"test/Task2\"\n",
    "solve_all_videos(videos_path,text_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
